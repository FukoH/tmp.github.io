<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>MIT6.828 学习笔记 | Shengxin Huang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Chapter 2 操作系统组织 操作系统的核心需求是同时支持多个活动  在进程间共享资源 保证不同的进程资源隔离 不同进程能够通信   为了满足上述三个需求，可以有许多方法。本课程主要关注单一核（monolithic kernal）的操作系统  本章也将讨论xv6启动时的第一个进程干了些什么  xv6 运行在多核（multi-core）的 RISC-V指令集的处理器上   2.1 物理资源抽象">
<meta name="keywords" content="操作系统">
<meta property="og:type" content="article">
<meta property="og:title" content="MIT6.828 学习笔记">
<meta property="og:url" content="http://yoursite.com/2020/08/13/MIT6-828笔记/index.html">
<meta property="og:site_name" content="Shengxin Huang">
<meta property="og:description" content="Chapter 2 操作系统组织 操作系统的核心需求是同时支持多个活动  在进程间共享资源 保证不同的进程资源隔离 不同进程能够通信   为了满足上述三个需求，可以有许多方法。本课程主要关注单一核（monolithic kernal）的操作系统  本章也将讨论xv6启动时的第一个进程干了些什么  xv6 运行在多核（multi-core）的 RISC-V指令集的处理器上   2.1 物理资源抽象">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2020/08/13/MIT6-828笔记/MIT6-828笔记/image-20210513112231474.png">
<meta property="og:image" content="http://yoursite.com/2020/08/13/MIT6-828笔记/MIT6-828笔记/image-20210514092232791.png">
<meta property="og:updated_time" content="2021-06-10T11:58:19.273Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MIT6.828 学习笔记">
<meta name="twitter:description" content="Chapter 2 操作系统组织 操作系统的核心需求是同时支持多个活动  在进程间共享资源 保证不同的进程资源隔离 不同进程能够通信   为了满足上述三个需求，可以有许多方法。本课程主要关注单一核（monolithic kernal）的操作系统  本章也将讨论xv6启动时的第一个进程干了些什么  xv6 运行在多核（multi-core）的 RISC-V指令集的处理器上   2.1 物理资源抽象">
<meta name="twitter:image" content="http://yoursite.com/2020/08/13/MIT6-828笔记/MIT6-828笔记/image-20210513112231474.png">
  
    <link rel="alternate" href="/atom.xml" title="Shengxin Huang" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Shengxin Huang</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Welcome to my site</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-MIT6-828笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/08/13/MIT6-828笔记/" class="article-date">
  <time datetime="2020-08-13T15:20:21.000Z" itemprop="datePublished">2020-08-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      MIT6.828 学习笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Chapter-2-操作系统组织"><a href="#Chapter-2-操作系统组织" class="headerlink" title="Chapter 2 操作系统组织"></a>Chapter 2 操作系统组织</h2><ul>
<li><p>操作系统的核心需求是同时支持多个活动</p>
<ul>
<li>在进程间共享资源</li>
<li>保证不同的进程资源隔离</li>
<li>不同进程能够通信</li>
</ul>
</li>
<li><p>为了满足上述三个需求，可以有许多方法。本课程主要关注单一核（monolithic kernal）的操作系统</p>
</li>
<li><p>本章也将讨论xv6启动时的第一个进程干了些什么</p>
</li>
<li><p>xv6 运行在多核（multi-core）的 RISC-V指令集的处理器上</p>
</li>
</ul>
<h3 id="2-1-物理资源抽象"><a href="#2-1-物理资源抽象" class="headerlink" title="2.1 物理资源抽象"></a>2.1 物理资源抽象</h3><ul>
<li>为什么要如此设计操作系统？<br>如果应用程序可以直接和硬件交互，应用程序必须运行良好，否则出现错误会影响其他其他程序</li>
</ul>
<h3 id="2-2-用户模式-user-mode-，特权模式（supervisor-mode"><a href="#2-2-用户模式-user-mode-，特权模式（supervisor-mode" class="headerlink" title="2.2 用户模式(user mode)，特权模式（supervisor mode)"></a>2.2 用户模式(user mode)，特权模式（supervisor mode)</h3><ul>
<li>强隔离需要在应用和操作系统之间有一个强边界，一个程序崩溃不会导致其他程序崩溃，这要求不同程序的指令，内存都互相隔离</li>
<li>CPU对隔离提供硬件级别的支持<ul>
<li>RISC-V有3中模式：machine mode,supervisor mode,user mode</li>
<li>CPU以machine mode 启动，之后很快切换到supervisor mode</li>
<li>supervisor mode可以执行特权指（如中断，读写寄存器等）,user mode只能执行用户空间内的指令</li>
<li>程序执行内核指令必须进入内核态，内核控制着进入内核态的权限</li>
</ul>
</li>
</ul>
<h3 id="2-3-内核结构"><a href="#2-3-内核结构" class="headerlink" title="2.3 内核结构"></a>2.3 内核结构</h3><ul>
<li>所有的指令都在内核态执行：monolithic kernel</li>
<li>内核只执行部分指令： microkernel</li>
</ul>
<h3 id="2-4-xv6组织"><a href="#2-4-xv6组织" class="headerlink" title="2.4 xv6组织"></a>2.4 xv6组织</h3><p>在kernel/目录下</p>
<h3 id="2-5-进程概述"><a href="#2-5-进程概述" class="headerlink" title="2.5 进程概述"></a>2.5 进程概述</h3><ul>
<li>隔离的抽象——进程</li>
<li>内核必须小心的实现进程的抽象</li>
<li>实现进程包括实现user/supervior mode的flag，地址空间，线程的时间片</li>
<li>进程给程序提供一个私有的地址空间，和显得像私有的CPU，其他进程无法访问</li>
<li>XV6的页表（由硬件实现）用来给进程提供私有空间，RISC-V的页表把虚拟地址映射到物理地址。虚拟地址是RISC-V指令操作的地址，物理地址是CPU获取主内存的指令的地址</li>
<li>VX6为每一个进程都提供一个页表，页表定义了进程的地址空间</li>
<li>每个地址空间的结构如图2.3，它从0开始，首先是用户数据，然后是用户栈，然后是堆。最顶端保留了一个区间用于tramploline，以及一个把进程的trapframe映射切换到内核的页</li>
<li>xv6内核用一个<em>struct proc</em>的struct维护了进程的状态，每个进程最重要的部分就是它的页表，内核栈，运行状态。</li>
<li>每个进程由线程执行具体的指令<ul>
<li>线程的执行可以暂停，稍后再继续</li>
<li>操作系统在进程间切换时，就是暂停了一个线程的执行，并切换到另一个线程</li>
<li>线程的状态（本地变量，函数，和返回地址）保存在线程的栈中</li>
<li>每个进程有两个栈，用户栈和内核栈（p-&gt;kstack)<ul>
<li>当进程执行具体指令时，只使用用户栈，内核栈为空</li>
<li>当进入内核态的时候，内核代码在内核栈内执行</li>
<li>当一个进程在内核态时，它的用户栈仍然保存着数据，但是此时数据并没有被使用</li>
<li>进程在用户中与内核栈之间换着执行，内核栈和用户栈是隔离的，用户栈满了也不影响内核栈</li>
</ul>
</li>
<li>进程通过调用RISC-V的<em>ecall</em>指令提升硬件的权限，并让程序进入内核态</li>
<li>进程通过调用RISC-V的<em>sret</em>指令降低硬件的权限，让程序返回到用户态</li>
<li>p-&gt;state指示了进程的状态，包括allocated，ready to run，running，waiting for I/O,existing</li>
<li>p-&gt;pagetable 保存了进程的页表，RISC-V硬件执行指令所需的指令，刚好以这种形式保存</li>
<li>页表也记记录着物理页面的地址，这些物理地址保存着进程的内存地址</li>
</ul>
</li>
</ul>
<h3 id="2-6-xv6的第一个进程如何启动"><a href="#2-6-xv6的第一个进程如何启动" class="headerlink" title="2.6 xv6的第一个进程如何启动"></a>2.6 xv6的第一个进程如何启动</h3><p>本节对内核是如何启动第一个进程的过程进行了概述。细节在以后的章节会展开。</p>
<ul>
<li><ol>
<li>Read-Only Memory上的boot loader把xv6内核加载到内存</li>
</ol>
</li>
<li><ol start="2">
<li>内核进入machine mode，CPU执行 <em>kernel/entry</em>下的_entry方法。此时RISC-V页表的硬件是失效的，虚拟地址直接映射到物理地址</li>
</ol>
</li>
<li>3.laoder把xv6的内核加载到0x80000000地址，不是加载到0x0的原因是0x0到0x80000000之间是I/O设备</li>
<li><ol start="4">
<li>在<em>kernel/start</em>里，_entry的指令创建了一个名叫stack0的栈，栈的寄存器指针<em>sp</em>的地址是stack0+4096,并且地址从高到低</li>
</ol>
</li>
<li>5.<em>kernel/start.c</em>里有一个<em>start</em>函数，它进行了一些仅在machine mode可以执行的配置，然后转换到supervisor mode。调用的是<em>mret</em>方法。这个方法也是系统提供的从supervisor mode回到 machine mode的方法。但是start.c里它是用来从machine mode进入supervisor mode的。</li>
<li>6.进入supervisor mode之前，<em>start</em>还做多了一件事：让时钟芯片产生时钟的interrupt。然后调用mret，开始执行main.c</li>
<li>7.<em>main.c</em>调用<em>userinit</em>创建第一个进程，第一个进程执行了<em>initcode.S</em>里的代码，又通过调用exec重新进入supervior mode。</li>
<li><ol start="8">
<li>exec把当前进程的内存和寄存器替换成新的程序（这里是<em>init</em>),执行完之后，在/init进程内返回到用户空间。<em>init.c</em>创建了一个新的console device file,并且打开文件描述符0，1，2。系统启动了。</li>
</ol>
</li>
</ul>
<h3 id="4-3-系统调用是如何执行的"><a href="#4-3-系统调用是如何执行的" class="headerlink" title="4.3 系统调用是如何执行的"></a>4.3 系统调用是如何执行的</h3><p>在第二章讲了执行init.S之后系统就进入了用户空间，那么在用户空间，又怎么进行系统调用呢？</p>
<ul>
<li><ol>
<li>exec的两个参数会被传到寄存器a0,a1,系统调用被存到a7，在<em>syscalls</em>数组内存放了系统调用的指针，<em>ecalls</em>中断并进入内核并执行<em>uservec</em>，<em>usertrap</em></li>
</ol>
</li>
<li><ol start="2">
<li><em>sys_call</em>方法从a7获取储存的数值，找到对应的系统调用</li>
</ol>
</li>
<li><ol start="3">
<li>sys_call把返回值存在p-&gt;trapframe-&gt;a0，用户空间的exec也会返回这个值</li>
</ol>
</li>
</ul>
<h3 id="4-4-系统调用的参数"><a href="#4-4-系统调用的参数" class="headerlink" title="4.4 系统调用的参数"></a>4.4 系统调用的参数</h3><ul>
<li>系统调用需要找到用户的代码传递的参数。通常传递的参数都放在寄存器里。内核的trap把寄存器保存到进程的trap frame，从而内核可以找到它们。<em>argint</em>，<em>argaddr</em>,<em>argfd</em>从trap frame获取系统调用的参数，分别以int，指针，或者文件描述符的类型读取参数。调用<em>argraw</em>来获取用户的寄存器</li>
<li>有的系统调用传递指针作为参数，内核需要使用这些指针来对内存进行读写<ul>
<li><ol>
<li>用户程序可能有bug，可能对内核的地址造成错误的操作带来问题</li>
</ol>
</li>
<li><ol start="2">
<li>xv6的内核页表和用户页表映射不一样，内核不能使用用户的页表</li>
</ol>
</li>
</ul>
</li>
<li><em>fetchstr</em>在内核态用来获取和传输数据到用户态的地址。它内部调用了copyinstr</li>
<li>copyinstr把max字节的数据从页表的虚拟地址srcva拷贝到dst地址</li>
<li>copyout把内核地址上的数据拷贝到用户地址上</li>
</ul>
<h2 id="Chapter-3-页表"><a href="#Chapter-3-页表" class="headerlink" title="Chapter 3 页表"></a>Chapter 3 页表</h2><ul>
<li>操作系统提供页表的机制，让每个进程拥有自己独立的地址空间，并且复用同一块物理内存</li>
<li>页表提供了一种让xv6施展一些小trick的机制（蹦床页表，trampoline page），在很多地址空间内，用一个未映射的页保护内核和用户栈</li>
<li>本章将解释RISC-V提供的页表以及xv6是如何使用它们的</li>
</ul>
<h3 id="3-1-分页的硬件"><a href="#3-1-分页的硬件" class="headerlink" title="3.1 分页的硬件"></a>3.1 分页的硬件</h3><ul>
<li><p>RISC-V的页表硬件把虚拟地址映射到物理地址</p>
</li>
<li><p>Sv39 RISC-V，如图3.1</p>
<ul>
<li>xv6运行在Sv39RISC-V上，意味着只有低位的39bit虚拟地址被使用了（虚拟地址有64bit），上部的25bit没有使用</li>
<li>按照Sv39的配置，RISC-V的页表在逻辑上由$2^27$个页表键值对（page table entries,PTEs)的数组组成，每一个PTE有一个44bit的物理页面号(Pyisical page number,PPN)和一些标志位（flags)</li>
<li>虚拟地址中，被使用的39bit中的上部的27bit是一个页表的索引，指向PTE。下12bit是offset</li>
<li>页表以4096byte（$ 2^12 $）的粒度控制物理地址，这样一个块被称为一个页面（page）</li>
</ul>
</li>
<li><p>顶部的25位没有被使用</p>
</li>
<li><p>PTE里还有10位留于未来的地址空间增长<br><img src="MIT6-828笔记/image-20210513112231474.png" alt="Figure 3.1: RISC-V virtual and physical addresses, with a simplified logical page table"></p>
</li>
<li><p>地址的转换步骤，如图3.2</p>
<p><img src="MIT6-828笔记/image-20210514092232791.png" alt="RISC-V address translation details"></p>
</li>
<li><p>页表在物理内存中被分为3层的树形结构</p>
<ul>
<li>用9位指向下一级的PTE</li>
<li>如果某一级的PTE需要转换的地址不存在，硬件会产生一个page-fault异常</li>
<li>PTE的10个bit的flag用于标识虚拟地址的可用性，见图3.2</li>
<li>硬件为了使用页表，内核必须把三级页表中的根页表的物理地址写入satp寄存器，每个CPU都有自己的satp寄存器，所以不同的CPU可以运行不同的进程，每个私有的地址空间都有它自己的页表维护</li>
<li>一些概念<ul>
<li>物理内存：DRAM的储存单元，一个字节的物理内存有一个地址</li>
<li>虚拟地址：指令只使用虚拟地址，分页硬件会把虚拟地址转为物理地址，DRAM硬件会对物理地址进行读写</li>
<li>虚拟内存：虚拟内存并不是一个物理对象，指的是内核提供的抽象机制，它抽象了物理内存和虚拟地址</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3-2-内核地址空间"><a href="#3-2-内核地址空间" class="headerlink" title="3.2 内核地址空间"></a>3.2 内核地址空间</h3><ul>
<li>Xv6为每个进程维护了一个页表，加上一个描述内核地址空间的页表</li>
<li>内核安排它自己的地址段分布，并控制它自己从可预测的虚拟地址访问物理内存和不同的硬件资源的权限</li>
<li>图3.3显示了虚拟地址是如何映射到物理地址的；<em>kernel/memlayout.h</em>定义了内核内存layout的常数</li>
<li>QUME的RAM（物理地址）从0x80000000开始，至少到0x86400000结束，被称为PYHTSTOP</li>
<li>0x80000000以下的地址是设备的地址，对这些地址的读写其实是对设备的读写</li>
<li>RAM和内存映射的设备寄存器使用的是直接映射策略，它们的物理地址和虚拟地址是一样的<ul>
<li>比如，kernel本身位于KERNBASE=0x80000000</li>
</ul>
</li>
<li>对物理地址和虚拟地址的直接映射简化了对物理地址的读写<ul>
<li>比如，调用fork的时候，为子进程分配内存，返回物理地址。fork拷贝父进程的内容到子进程的时候，会直接使用那个物理地址作为虚拟地址</li>
</ul>
</li>
<li>也有很多不是直接映射的地址<ul>
<li>trampoline page.位于虚拟地址顶部的地址空间，映射了两次，一次是直接映射，一次是虚拟地址的顶部</li>
<li>kernel的栈页.每个进程都有自己的内核栈，它们都被映射到了比较高的地址，所以低地址就是未被映射的<em>guard page</em>。guard page的PTE是不可用的（PTE_V位没有设置），如果kernerl 栈溢出了，很有可能会导致内核混乱。如果没有guard page，溢出的栈会覆盖其他内核的内存，导致崩溃</li>
</ul>
</li>
<li>如果在高地址也采用直接映射，提供guard page会使用未映射的虚拟地址，导致管理困难</li>
</ul>
<h3 id="3-3-Code-创建一个地址空间"><a href="#3-3-Code-创建一个地址空间" class="headerlink" title="3.3 Code:创建一个地址空间"></a>3.3 Code:创建一个地址空间</h3><ul>
<li>管理地址空间和页表的代码位于<em>kernel/vm.c</em><ul>
<li>核心的数据结构是<em>pagetable_t</em>，本质是一个指针，指向RISC-V根页面</li>
<li>pagetable_t可能是kernel的页表，也可能是某一进程的页表</li>
<li>核心函数是<em>walk</em>,它为一个虚拟地址找到PTE。也寻找mappages装载新的映射。</li>
<li>以<em>kvm</em>开头的函数控制内核页表</li>
<li>以<em>uvm</em>开头的函数控制用户页表</li>
<li>其他函数用户页表和内核页表都在用</li>
<li><em>copyin</em>从用户的虚拟地址拷贝数据，<em>copyout</em>拷贝数据到用户的虚拟地址</li>
</ul>
</li>
<li>系统boot的时候，main函数调用kvminit创建了内核页表<ul>
<li>发生在分页启动之前，所以是直接作用在物理地址上的</li>
<li>先调用kvminit创建页表，kvminit调用kvmmap传输数据和指令等</li>
<li>walk函数查询PTE寻找虚拟地址，依次遍历三层</li>
<li>main调用了kvminithart，安装了内核的页表，把根页面装入satp寄存器</li>
<li>procinit在main中被调用，为每个进程分配内核栈</li>
<li>每个RISC-V的CPU把页表的PTE暂存到TLB中（translation look-aside buffer），页表变化时，xv6必须通知CPU更新TLB。</li>
</ul>
</li>
</ul>
<h3 id="3-4-物理内存分配"><a href="#3-4-物理内存分配" class="headerlink" title="3.4 物理内存分配"></a>3.4 物理内存分配</h3><ul>
<li>内核必须在运行时为页表，用户内存，内核栈和管道分配物理内存</li>
<li>xv6在内核的尾部和PHTSTOP之间的地址用于运行时的物理地址分配</li>
<li>每次一次性的分配和释放整个4096byte的整个页面。它用一个线程，用一个linked list记录了哪些页面被使用，分配内存就从链表里移除页面，释放内存就向链表添加页面</li>
</ul>
<h3 id="3-5-代码：物理内存分配器"><a href="#3-5-代码：物理内存分配器" class="headerlink" title="3.5 代码：物理内存分配器"></a>3.5 代码：物理内存分配器</h3><ul>
<li>内存分配器位于<em>kalloc.c</em></li>
<li>分配器的数据结构是<em>freelist</em></li>
<li>每个页面的结构是<em>struct run</em></li>
<li>free list 由spin lock保护，如果对free list读写需要acquire和release锁</li>
<li>kinit 执行一些初始化操作</li>
<li>kfree 和 kalloc释放和分配内存页，函数内对freelist进行增加和删除操作</li>
</ul>
<p>###3.6 进程地址空间</p>
<ul>
<li>每个进程有自己的页表，xv6在进程间切换时，页表也会变化</li>
<li>进程的用户内存可以从虚拟地址的0一直到MAXVA，总共256G的地址空间</li>
<li>xv6使用kalloc分配物理内存，然后把PTE添加到进程的页表，页表指向新的物理内存，xv6设置了PTE_W，PTE_R,PTE_U，PTE_V的标志位</li>
<li>例子<ul>
<li>不同的进程的页表都把用户空间的地址转换到不同的物理页面</li>
<li>每个进程都认为它自己拥有连续的从0开始的虚拟地址。事实上，物理地址可能不是连续的</li>
<li>内核把页面顶部的tampoline页面也映射了，从而单一的物理内存在所有的私有地址空间里都可以看到它</li>
</ul>
</li>
<li>为了防止用户栈溢出，在栈的下面也放置了一页保护页。栈溢出时会访问到该保护页，从而出现缺页错误异常，用户进程因此陷入内核并等待处理，内核可能会终止掉该进程。而现在的操作系统在这种情况下，一般都会自动地为用户栈分配更多的空间。</li>
</ul>
<h3 id="3-7-Code-sbrk"><a href="#3-7-Code-sbrk" class="headerlink" title="3.7 Code:sbrk"></a>3.7 Code:sbrk</h3><ul>
<li>Sbrk是一个系统调用，用户进程调用它以增加或减少自己拥有的物理内存（proc-&gt;sz）。</li>
<li>sbrk调用growproc。growproc根据增加或减少内存的需要，又分别调用uvmmalloc和uvmdealloc来满足请求。</li>
<li>uvmalloc通过调用kalloc来分配物理内存，并调用mappages来更新页表，并设置PTE的5个标志位都置位。</li>
<li>uvmdealloc调用uvmunmap来回收已分配的物理内存。</li>
<li>uvmunmap使用walk找到相应的PTE，并且调用kfree回收相应的物理帧。在xv6中，用户进程的页表不仅告诉了分页硬件如何转换虚拟地址，也记录着哪些物理帧被分配给该用户进程，因此在回收分配给用户的物理帧之前，应该先检查相关的PTE是否存在/有效。</li>
</ul>
<h3 id="3-8-Code：exec"><a href="#3-8-Code：exec" class="headerlink" title="3.8 Code：exec"></a>3.8 Code：exec</h3><ul>
<li>现在我们来看最后一段代码，系统调用exec的实现（kernel/exec.c）。我们之前知道，系统调用exec将存储在文件系统上的，新的用户程序装载进内存里，然后执行它。现在我们将进一步观察，在exec中，这个新用户进程的虚拟地址空间是怎么被建立起来的。</li>
</ul>
<blockquote>
<p>int exec(char *path, char **argv)</p>
<ul>
<li>exec通过路径名打开文件，然后读取该文件的ELF Header（kernel/elf.h）。xv6的所有应用程序以通用的ELF格式来描述，一个ELF二进制文件大概这样组成（更准确的定义，建议查阅相关资料，这里进行简单的不严谨的说明）：一个ELF Header，后面紧跟一系列的Program Section Headers。每个Program Section Header都对应一段需要加载到内存中的程序，xv6的应用程序只有一个Program Section Header，而在其它操作系统上可能有好几个。</li>
<li>exec读取了文件系统上的文件之后，第一件事就是先检查该文件是否包含ELF二进制文件。</li>
<li>接着，exec为用户进程调用proc_pagetable，通过uvmcreate创建一个空的用户页表，接着只在该页表上添加了trampoline和trapframe的映射，其它的虚拟地址空间都暂时为空。</li>
<li>然后，exec对于每个程序段，先是调用uvmalloc分配足够的物理帧，更新了用户页表。然后调用loadseg加载程序段到这些物理帧中。loadseg将虚拟地址传给walkaddr，walkaddr又通过walk查找相关PTE，将va转换为pa，最后walkaddr成功返回uvmalloc分配的物理帧的物理地址，loadseg再调用readi，真正地将程序段加载到物理内存中。</li>
<li>至此，exec已经将用户程序的各程序段都装载完成了。现在exec分配并初始化用户栈。</li>
</ul>
</blockquote>
<ul>
<li>exec首先分配两页物理帧。第一页用作保护页，通过调用uvmclear将PTE_U设为无效，这样在用户空间下不能访问它；第二页留给用户栈，从栈顶开始，将命令行参数的字符串、指向这些命令行参数的指针数组argv[ ]、用于从调用main(argc, argv[ ])返回的其它参数（argc、argv指针和伪造的返回pc值）推入用户栈内。</li>
</ul>
<h3 id="3-8-真实世界"><a href="#3-8-真实世界" class="headerlink" title="3.8 真实世界"></a>3.8 真实世界</h3><ul>
<li><p>xv6和许多操作系统一样，使用分页的方式构建虚拟内存系统，管理内存空间；使用页表完成虚拟地址到物理地址的转换。现代操作系统会使用更复杂的分页机制来构建虚拟内存系统。</p>
</li>
<li><p>对于xv6的内核，我们使用了直接映射的方式，因为我们假定RAM会被加载到固定的物理地址，因此内核也被加载到相同的位置，这是一种简化的解决方案，因为我们使用QEMU仿真所有硬件。事实上，对于真实的硬件来说这并不是一个好主意，在现实中硬件会将RAM、各种设备加载到一个无法预知的物理地址，RAM的起始地址就不再是固定的。一种更为严格的内核设计方式是，利用页表，将任意的硬件物理内存布局转换为可预测的内核虚拟地址布局。</p>
</li>
<li><p>分页可以有不同的粒度。如果本身就内存紧缺，仍然坚持使用大页可能会产生很多的内部碎片，这时应该使用不那么大的页；但是如果你的内存充足，使用大页，能显著地减少操作页表带来的开销。因此，分页的大小最好取决于你拥有多大的RAM。</p>
</li>
<li><p>虽然xv6内核有内存分配器kalloc，但是它并不像广知的malloc那样，内核无法根据需要，动态地给一些复杂数据结构分配内存（如果是malloc的话，你就可以使用sizeof( )）。此外，xv6的内存分配器，只分配大小为一页（4KB）的块；更精细的内存分配器，应该能够分配多种不同大小的块，以满足更多不同需求。</p>
</li>
</ul>
<h2 id="Chapter-4-中断"><a href="#Chapter-4-中断" class="headerlink" title="Chapter 4 中断"></a>Chapter 4 中断</h2><p>CPU在执行指令时，有些事件会让系统从内核态切回到用户态。有时候会有一些非法的指令，或者用户程序执行了一些系统调用。在处理这些事件的时候主要面临3大挑战：</p>
<ol>
<li>内核必须管理好内核态与用户态之间的切换</li>
<li>内核和设备必须处理好并行的事情</li>
<li>内核必须明白设备的接口</li>
</ol>
<p>本章主要讲述xv6是如何处理这3个问题的。<br>在操作系统中，有三种情况会导致CPU的控制流发生转移：</p>
<ol>
<li>系统调用：用户态中通过ecall指令进入内核态</li>
<li>异常：异常发生，如除零、访问非法地址</li>
<li>中断：设备中断，如硬盘完成读写请求</li>
</ol>
<ul>
<li><p>本书统称这三种情况为”trap”。陷阱在一般情况下应该是透明的，即当执行完处理程序后能够恢复之前程序的状态。这就要求在陷入内核态时，内核要保存之前的寄存器等状态信息，当执行完处理程序之后再进行恢复。</p>
</li>
<li><p>一般由内核负责发起一个中断，而不是进程，因为只有内核才有对应的权限</p>
</li>
<li><p>三种情况下，一般操作系统会负责以下事情：</p>
<ul>
<li>保存寄存器的状态，以便未来的切换</li>
<li>建立系统在内核中执行</li>
<li>系统选择一个地方让内核开始执行</li>
<li>内核必须搜集事件的信息</li>
<li>系统必须保证内核和进程的独立</li>
</ul>
</li>
<li><p>操作系统必须知道硬件处理这三种情况的细节，在大多数操作系统中都是由同一种机制解决的</p>
</li>
<li><p>中断发生的时候，中断了处理器的指令执行，并且触发一个新的代码序列<em>interupt handler</em>。触发之前，处理器会把当前寄存器储存起来，以便中断处理完成后能恢复现场。当中的挑战是内核态和用户态的切换。</p>
</li>
<li>异常（本书也称为trap）由当前正在执行的进程引发，中断则可能并发的发生于进程之外（比如设备读写之后中断另一个进程）</li>
<li><p>陷阱在一般情况下应该是透明的，即当执行完处理程序后能够恢复之前程序的状态。这就要求在陷入内核态时，内核要保存之前的寄存器等状态信息，当执行完处理程序之后再进行恢复。</p>
</li>
<li><p>在XV6中处理陷阱有以下四步：CPU进行硬件操作，汇编向量被设置，C陷阱处理程序决定如何处理，系统调用或设备驱动处理该陷阱。内核中通常分三种情况来分别处理这些陷阱：用户态陷阱、内核态陷阱、时钟中断。</p>
</li>
</ul>
<h3 id="4-1-RISC-V的陷阱运行机制"><a href="#4-1-RISC-V的陷阱运行机制" class="headerlink" title="4.1 RISC-V的陷阱运行机制"></a>4.1 RISC-V的陷阱运行机制</h3><p>RISC-V的CPU有一套寄存器，内核会读写寄存器，从而告诉CPU如何处理traps。最重要的寄存器是以下几个：<br>stvec：陷阱处理程序入口，CPU会跳转到此处来处理陷阱<br>sepc：保存陷阱发生时的pc，使用sret指令会将pc恢复<br>scause：陷阱原因<br>sscratch：内核保存特定的值，见下文<br>sstatus：sstatus中的SIE位控制中断是否允许；SPP位表示陷阱来自用户模式还是监管模式。</p>
<ul>
<li>这些寄存器只能在supervisor mode下读写，不能在user mode下读写</li>
<li>多核CPU上，每一个核都有一套这些寄存器，它们可能同时都在处理中断</li>
<li>CPU不会切换到内核的页表，内核的栈，也不会保存除了pc以外的寄存器。这些都由内核完成。CPU在trap中不怎么工作是为了给软件提供灵活性。这样设计可以给软件更好的灵活性。而设置pc的工作必须由硬件完成，因为当切换到内核态时，用户指令可能会破坏隔离性。</li>
</ul>
<h3 id="4-2-用户态的trap"><a href="#4-2-用户态的trap" class="headerlink" title="4.2 用户态的trap"></a>4.2 用户态的trap</h3><ul>
<li>XV6的用户态陷阱处理流程如下：uservec -&gt; usertrap -&gt; usertrapret -&gt; userret。<br>由于CPU不会进行页表切换，因此用户页表必须包含uservec函数（stvec所指向的函数）的映射。该函数要将satp切换为内核页表，为了切换后的指令能继续执行，该函数必须在用户页表和内核页表中有相同的地址。为了满足上述要求，XV6将一个叫trampoline的页映射到相同的虚拟地址TRAMPOLINE，其中包含了trampoline.S的指令，并设置stvec为uservec。<h4 id="uservec"><a href="#uservec" class="headerlink" title="uservec"></a>uservec</h4>在进入uservec函数时，所有的32个寄存器都是被中断代码所享有的，而uservec需要使用寄存器来执行指令，因此，RISC-V提供了sscratch寄存器，通过csrrw a0, sscratch, a0指令，保存a0，之后就可以使用a0寄存器了。<br>之后，函数就需要保存所有用户寄存器到trapframe结构体中，该结构体的地址在进入用户模式之前，被保存在sscratch寄存器中，因此经过之前的csrrw操作后，就被保存在a0中。当创建进程时，内核会申请一个页面保存trapframe，该页面就位于TRAMPOLINE下方，进程的p-&gt;trapframe也指向该页面。<br>最后，函数从trapframe中取出内核栈地址、hartid、usertrap的地址、内核页表地址，切换页表，跳转到usertrap函数。<h4 id="usertrap"><a href="#usertrap" class="headerlink" title="usertrap"></a>usertrap</h4>usertrap的工作即判断陷阱类型并处理，最后返回。函数首先将stvec设置为kernelvec的地址，使内核态发生的中断由kernelvec函数来处理。之后保存sepc寄存器，防止其被覆盖。然后判断陷阱类型，如果是系统调用，就将pc指向ecall的下一条指令，然后交给syscall函数处理；如果是设备中断，就交给devintr；否则就是异常，那么就终止该进程的运行。在最后会判断进程是否已经被杀死或者当发生时钟中断时，让出处理器。<h4 id="usertrapret"><a href="#usertrapret" class="headerlink" title="usertrapret"></a>usertrapret</h4>该函数首先将stvec设置为uservec的地址，之后设置trapframe（这些内容在uservec中会使用到），然后恢复sepc寄存器。最后，调用userret函数。<br>最后，在userret函数中进行与uservec相反的步骤，将页表和寄存器进行恢复。</li>
</ul>
<h3 id="4-3-系统调用"><a href="#4-3-系统调用" class="headerlink" title="4.3 系统调用"></a>4.3 系统调用</h3><p>以initcode.S中的系统调用为例，将两个参数分别放在a0 a1寄存器中，将系统调用号放在a7寄存器中，然后执行ecall指令。</p>
<h1 id="exec-init-argv"><a href="#exec-init-argv" class="headerlink" title="exec(init, argv)"></a>exec(init, argv)</h1><p>.globl start<br>start:<br>        la a0, init<br>        la a1, argv<br>        li a7, SYS_exec<br>        ecall</p>
<p>而在syscall函数中，会取出a7的值，然后查找syscalls数组，找到相应的处理函数即sys_exec，交由该函数进行处理，最后将返回值放在trapframe-&gt;a0中。</p>
<h3 id="4-4-内核态陷阱"><a href="#4-4-内核态陷阱" class="headerlink" title="4.4 内核态陷阱"></a>4.4 内核态陷阱</h3><p>内核态陷阱的处理路径为：kernelvec -&gt; kerneltrap -&gt; kernelvec<br>kernelvec<br>由于陷阱发生在内核态，因此，不需要对satp和栈指针进行处理，只需要保存所有通用寄存器即可。之后跳转到kerneltrap进行处理，当该函数返回后，再恢复所保存的寄存器。<br>kerneltrap<br>kerneltrap只需要处理两种陷阱：设备中断和异常。通过调用devintr判断是否为设备中断，如果不是设备中断，那么就是异常，且该异常发生在内核态，内核调用panic函数终止执行。如果是时钟中断，那么就让出处理器。由于yield函数会导致sepc sstatus寄存器被修改，因此在kerneltrap中要对其进行保存和恢复。</p>
<h3 id="4-6-缺页异常"><a href="#4-6-缺页异常" class="headerlink" title="4.6 缺页异常"></a>4.6 缺页异常</h3><p>在XV6中，并没有对异常进行处理，仅仅是简单地kill或panic。而在真实操作系统中，会对异常进行具体的处理。例如使用缺页异常来实现COW（copy on write）fork。<br>在RISC-V中，有三种不同的缺页异常：load page faults（当load指令转换虚拟地址时发生），store page faults（当store指令转换虚拟地址时发生），instruction page faults（当指令的地址转化时发生）。在scause寄存器中保存了异常原因，stval中保存了转换失败的地址。<br>COW fork使子进程与父进程享有相同的物理页面，但是设置为只读的。当子进程或父进程执行store指令时，就会触发异常，此时再对页面进行拷贝，然后以读写的模式映射到父子进程的地址空间。<br>另一种技术是lazy allocation，当应用调用sbrk时，增长地址空间，但在页表中标记新地址为无效的。当在新地址上发生缺页异常后，才真正地分配物理页面给进程。<br>paging from disk即虚拟内存，操作系统选择一部分保存到磁盘上并标记页表项为无效，当读写该页面时再从磁盘中取回内存。除此之外，还有如automatically extending stacks 和 memory-mapped files等技术也使用了缺页异常。</p>
<h2 id="Chapter-5-中断和设备驱动"><a href="#Chapter-5-中断和设备驱动" class="headerlink" title="Chapter 5 中断和设备驱动"></a>Chapter 5 中断和设备驱动</h2><p>驱动是操作系统中用于管理特定设备的代码：驱动控制设备硬件，通知硬件执行操作，处理中断，与等待该设备IO的进程进行交互。<br>当设备需要与操作系统进行交互时，就会产生中断（陷阱的一种），之后内核的陷阱处理代码就会识别中断设备并调用对应的驱动处理程序。在XV6这一步发生在trap.c的devintr中。<br>大部分设备驱动在两个上下文中执行代码：顶层部分运行在进程的内核线程中，底层部分在中断处理时执行。顶层部分通过系统调用如read和write来调用，这一部分代码会请求硬件开始一个操作的执行（如请求硬盘读取块）；之后就会进入等待状态等待操作的完成。当设备完成操作后，就会触发一个中断，驱动的中断处理程序，即底层部分就会判断完成的操作，唤醒对应的正在等待的进程，之后通知硬件执行下一个操作。</p>
<h3 id="代码：控制台输入"><a href="#代码：控制台输入" class="headerlink" title="代码：控制台输入"></a>代码：控制台输入</h3><p>控制台的驱动程序console.c是一个驱动结构的简单抽象。控制台驱动通过UART（Universal asynchronous receiver-transmitter，通用异步收发传输器）串口读取用户输入的字符。驱动程序一次会累积一行的输入，并处理特定的字符如退格和ctrl-u。用户进程通过read系统调用来获取一行输入。<br>驱动调用的UART硬件是由QEMU模拟的16550芯片，一个16550芯片可以管理一条连接到终端或其他电脑的RS232串行链路。在QEMU中，其连接到键盘和显示器。<br>UART硬件可以看作一组映射到内存中的控制寄存器，对硬件的控制可以直接通过load和store特定内存来完成。UART内存映射地址开始于0x10000000或UART0（定义于memlayout.h）。每个控制寄存器的大小为1byte，偏移量定义于uart.c。<br>XV6main函数中的consoleinit对UART设备进行初始化，设置UART设备每接收一个字节的输入就产生一个接收中断，每当完成一个字节输出的发送时就产生一个传输完成中断。<br>XV6 shell通过init.c中打开的文件描述符对控制台进行读取。read系统调用将会调用consoleread函数，该函数等待输入的到达（通过中断）并保持在cons.buf中，拷贝其到用户空间，当一整行接收完成后返回到用户进程中。如果没有一整行输入到达，read进程就会在sleep调用中等待。<br>当用户输入一个字符，UART设备就会产生一个中断，激活XV6的陷阱处理程序。陷阱处理程序将会调用devintr，读取scause判断是否为外部设备产生的中断。之后通过PLIC（平台级中断控制器）判断中断设备，如果是UART设备，就会调用uartintr函数。<br>uartinit从UART设备中读取所有输入字符，并将其交给consoleintr处理，此函数不会等待字符的输入，因为未来的输入会产生新的中断。consoleintr将输入保持在buffer中直到一整行到达，同时对一些特殊符号进行处理。当一整行到达后，就会唤醒一个正在等待的consoleread。<br>当consoleread被唤醒时，buffer中就保存了完整的一行输入，此时就可以将其拷贝到用户空间并返回。</p>
<h3 id="代码：控制台输出"><a href="#代码：控制台输出" class="headerlink" title="代码：控制台输出"></a>代码：控制台输出</h3><p>write系统调用对控制台的写入最终会调用uartputc函数，设备会维护输出缓冲uart_tx_buf，因此写进程不需要等待UART完成发送。uartputc将字符加入缓冲区后，调用uartstart函数开始传输之后返回，该函数唯一的等待情况是缓冲区已满。<br>每当UART发送一个字节后，就会产生一次中断。uartintr函数会调用uartstart函数判断传输是否完成，未完成就开始传输下一个缓冲的字符。因此，当进程写入多个字符时，第一个字节会通过uartputc调用uartstart进行传输，之后的字节将会被uartintr调用的uartstart进行传输。<br>对于设备活动和进程活动，常用的解耦方式是通过缓冲和中断。控制台驱动可以处理输入即使没有进程在等待读取，一个随后到来的read会读取到输入。类似的，进程可以进行输出而不需要等待设备响应。解耦可以允许进程并行执行设备IO从而提高性能，尤其是当设备速度很慢或需要立即进行响应（如输入一个字符）。这种思想也被称作I/O并行。<br>驱动中的并行<br>在consoleread和consoleintr中会调用acquire函数。这些调用会申请一个锁，用于在并行访问中保护驱动的数据结构。在这里有三种并行风险：两个不同CPU上的进程同时调用consoleread；当CPU在执行consoleread函数时硬件触发了一个中断；当consoleread在执行时，硬件在其他CPU上触发了一个中断。<br>在并行中需要关注的另一个点是一个进程可能会等待设备的输入，但是中断信号在另一个进程运行时产生，因此中断处理程序是必须上下文无关的（不允许考虑中断时的进程或代码）。例如中断处理程序不能安全地在当前进程地页表上调用copyout函数。中断处理程序应该仅执行上下文无关的工作（如拷贝输入到缓冲区），之后唤醒顶层部分来处理剩余工作。</p>
<h3 id="定时器中断"><a href="#定时器中断" class="headerlink" title="定时器中断"></a>定时器中断</h3><p>XV6通过定时器中断来维护时钟以及进行进程切换；在usertrap和kerneltrap中的yield函数会执行进程切换。定时器中断会由RISC-V CPU内部的时钟硬件产生。XV6对此时钟硬件进行编程以定期中断每个CPU。<br>RISC-V要求定时器中断必须在机器模式下执行，而不是在监管模式下执行。RISC-V的机器模式在无分页环境下执行，并且具有一系列单独的控制寄存器，因此在机器模式下运行普通的 xv6 内核代码是不切实际的。所有XV6的定时器中断处理程序是和陷阱机制完全分开的。<br>start.c中的代码执行于机器模式中，main函数之前，在timerinit函数中对定时器中断进行了设置：对CLINT硬件编程使其在一定时间后产生一次中断；设置scratch区域（类似于trapframe），帮助定时器中断处理程序保存寄存器和CLINT寄存器的地址。最后函数会设置mtvec为timervec函数地址并开启定时器中断。<br>定时器中断会在任何时候发生，内核在执行关键操作时也无法禁用定时器中断。因此定时器中断处理程序必须保证不会干扰被中断的内核代码执行。处理程序最基本的策略就是产生一个软件中断之后立即返回。产生的软件中断就可以通过通用的陷阱机制进行处理，并且可以进行关闭。软件中断的处理程序在devintr函数中。<br>机器模式的时钟中断向量为timervec，该函数保存了三个寄存器在start函数准备的scratch区域中，通知CLINT下一个中断的时刻，通过csrw sip, a1（a1为2）指令触发一个软件中断，最后恢复寄存器并返回。</p>
<h3 id="真实操作系统"><a href="#真实操作系统" class="headerlink" title="真实操作系统"></a>真实操作系统</h3><p>XV6运行设备和时钟中断在内核执行时产生。定时器中断在中断处理程序中强制线程切换，即使是在内核态执行中。这个功能可以使得内核线程公平地获取CPU时间片，尤其是当内核线程耗费大量时间进行计算而不返回用户态。但是，这使得内核代码需要考虑到其可能会被暂停并在一段时间后再另一个CPU上恢复，而这给XV6带来了一定的复杂性。如果设备中断和定时器中断只在用户代码执行时运行触发，内核可以变得更加简单。<br>在许多操作系统中，驱动程序的代码量远远大于内核本身。要支持所有设备在计算机上运行是十分繁杂的工作：有大量设备需要支持，设备有很多特性，设备间的协议十分复杂并且缺少文档。<br>UART设备通过读取控制寄存器一次接收一个字节数据，这种模式称为程序I/O（programmed I/O），因为数据移动由软件驱动。这种方式十分简单但是在高速设备上是十分缓慢的。高速设备通常通过DMA方式来进行数据传输。DMA设备硬件可以直接对内存进行读写，现代硬盘和网络设备就是通过这种方式进行的。DMA设备驱动会在内存中准备数据，之后通过一次控制寄存器的写入告诉设备对准备好的数据进行处理。<br>当设备需要在无法预知但不太频繁的时间上需要进行处理时，中断是有效的。但是中断有很大的CPU开销。因此高速设备会使用一些技巧来减少中断次数。一个技巧就是对一整批的输入或输出请求发起一次中断。另一个是驱动完全禁用中断，转为定时查询设备是否需要处理，这种技术被称为轮询（polling）。如果设备操作执行非常频繁，那么轮询是有意义的，反之如果设备大部分时间都是空闲的，那么轮询会浪费CPU时间。一些驱动会根据设备负载自动切换轮询和中断。<br>UART驱动先拷贝输入数据到内核缓冲区，之后再拷贝到用户空间。这在低数据传输率的情况下是有效的，但是对于高速设备，两次拷贝会显著地降低性能。一些操作系统可以直接将数据在用户态缓冲区和设备硬件之间移动，通常是通过DMA。</p>
<h3 id="Chapter-6-锁"><a href="#Chapter-6-锁" class="headerlink" title="Chapter 6 锁"></a>Chapter 6 锁</h3><ul>
<li>在包括XV6的绝大部分操作系统都是多个任务交错执行的。交错的一个原因是多核硬件：多核计算机的多个CPU核心独立执行计算，如XV6的RISC-V处理器。</li>
<li>多个CPU核心共享物理内存，XV6利用这种共享来维护所有核心都会读写的数据结构。而这种共享会导致一个CPU在读取某数据结构时，可能有另一个CPU正在对此数据进行更新；或者多个CPU同时更新同一个数据。如果不对这种并行访问进行小心的设计，就可能会导致错误的结果产生或者损坏数据。</li>
<li><p>即使是单核处理器，内核也可能会在多个线程之间进行切换，导致它们交错运行。最后，如果中断在错误的时间发生，设备中断处理程序也可能会对数据造成损坏。并发一词就是指由于多核并行、线程切换或中断，导致多个指令流交错执行。</p>
</li>
<li><p>内核中充满了被并发访问的数据。如两个CPU可以同时调用kalloc，从而同时从空闲链表的中弹出空闲页。内核设计者必须允许大量并发，因为并发可以提高系统的性能和响应速度。然而，系统设计者需要耗费很多精力来保证并发的正确性。有很多种方法可以写出正确的代码，其中有一些比其他更容易推理。针对并发的正确性以及支持它们的抽象的策略被称为并发控制技术。</p>
</li>
<li><p>XV6基于不同的情况使用了多种并发控制技术，并且还有更多技术可以使用。其中一个广泛使用的技术就是锁。锁可以提供互斥性，保证同一时间只有一个CPU能够持有锁。如果程序员将共享数据与锁进行关联，在代码使用这些数据时就必须持有相应的锁，这样就可以保证同一时间只有一个CPU能使用该数据。尽管锁是一种容易理解的并发控制机制，但锁的缺点是其会降低性能，因为锁将并发操作串行化。</p>
</li>
</ul>
<p>在包括XV6的绝大部分操作系统都是多个任务交错执行的。交错的一个原因是多核硬件：多核计算机的多个CPU核心独立执行计算，如XV6的RISC-V处理器。多个CPU核心共享物理内存，XV6利用这种共享来维护所有核心都会读写的数据结构。而这种共享会导致一个CPU在读取某数据结构时，可能有另一个CPU正在对此数据进行更新；或者多个CPU同时更新同一个数据。如果不对这种并行访问进行小心的设计，就可能会导致错误的结果产生或者损坏数据。即使是单核处理器，内核也可能会在多个线程之间进行切换，导致它们交错运行。最后，如果中断在错误的时间发生，设备中断处理程序也可能会对数据造成损坏。并发一词就是指由于多核并行、线程切换或中断，导致多个指令流交错执行。<br>内核中充满了被并发访问的数据。如两个CPU可以同时调用kalloc，从而同时从空闲链表的中弹出空闲页。内核设计者必须允许大量并发，因为并发可以提高系统的性能和响应速度。然而，系统设计者需要耗费很多精力来保证并发的正确性。有很多种方法可以写出正确的代码，其中有一些比其他更容易推理。针对并发的正确性以及支持它们的抽象的策略被称为并发控制技术。<br>XV6基于不用的情况使用了多种并发控制技术，并且还有更多技术可以使用。其中一个广泛使用的技术就是锁。锁可以提供互斥性，保证同一时间只有一个CPU能够持有锁。如果程序员将共享数据与锁进行关联，在代码使用这些数据时就必须持有相应的锁，这样就可以保证同一时间只有一个CPU能使用该数据。尽管锁是一种容易理解的并发控制机制，但锁的缺点是其会降低性能，因为锁将并发操作串行化。</p>
<h3 id="6-1-竞争条件"><a href="#6-1-竞争条件" class="headerlink" title="6.1 竞争条件"></a>6.1 竞争条件</h3><p>假如两个进程在不同的CPU上同时调用wait函数释放子进程内存，导致在每个CPU上，内核都会调用kfree来释放子进程的页面。内核维护了一个空闲页面链表，kalloc会pop一个页面，而kfree会push一个页面。为了最佳的性能，我们希望两个父进程的kfree能够并行执行而不需要等待另一个，但是在XV6的kfree实现中是不正确的。<br>一种竞争条件是指一个内存位置被并发访问，并且至少一个访问是写入。竞争通常是bug的信号，要么更新发生丢失，要么读取到不完整的数据更新。竞争的结果取决于两个CPU执行的实际时间以及对内存的操作如何被内存系统排序，这些会使得竞争导致的bug难以复现和调试。例如插入print语句来调试可能会改变执行的时间从而使得竞争消失。<br>struct element *list = 0;<br>struct lock listlock;</p>
<p>void<br>push(int data)<br>{<br>  struct element <em>l;<br>  l = malloc(sizeof </em>l);<br>  l-&gt;data = data;<br>  acquire(&amp;listlock);<br>  l-&gt;next = list;<br>  list = l;<br>  release(&amp;listlock);<br>}</p>
<p>当我们说锁保护了数据，实际的意思是锁保护了应用在数据上的一系列不变性。一个操作的正确性取决于操作开始时的不变性是否正确。操作可能会暂时违反不变性，但必须在在操作结束前恢复其不变性。例如对于链表，不变性时指头指针指向第一个元素，且每一个元素的next域指向下一个元素。push操作的l-&gt;next = list会暂时破坏其不变性，使得头指针并不是指向第一个元素。竞争条件发生因为在另一个CPU上的操作依赖于不变性，而这被暂时破坏了。锁的使用可以保证在数据结构上一次只有一个CPU在临界区执行，因此不会有CPU在不变性被破坏时执行操作。<br>可以认为锁将并发的临界区串行化使其一次只能执行一个，从而保护了不变性。也可以认为被锁保护的临界区对于其他临界区来说是原子性的，因此每一个都只能看见一系列先前临界区的完整修改，而永远不会看见部分修改。<br>尽管锁的正确使用可以使错误代码变正确，但锁也限制了性能。例如当两个进程同时调用kfree，锁会将两个调用串行化，将它们在不同的CPU上运行就不会获得收益。在内核设计中一个大的挑战就是避免锁争用。XV6在这方面做的很少，但是复杂的内核会通过特殊的方法组织数据结构和算法来避免锁争用。例如内核会为每个内核维护一个独立的空闲内存链表，只有当当前CPU的链表为空时才会去请求其他CPU的链表来获取空闲内存。而其他的争用可能需要更加复杂的设计。<br>锁的位置同样对性能影响很大。例如在push中可以将acquire放在更加前面，但这就会降低性能，因为malloc的调用也被串行化。</p>
<h3 id="6-2-代码：锁"><a href="#6-2-代码：锁" class="headerlink" title="6.2 代码：锁"></a>6.2 代码：锁</h3><p>XV6中有两种锁：自旋锁和睡眠锁。自旋锁定义为struct spinlock，最重要的域就是locked，1代表被持有而0代表未被持有。理论上xv6可以通过下列代码来上锁：<br>void<br>acquire(struct spinlock *lk) // does not work!<br>{<br>  for(;;) {<br>    if(lk-&gt;locked == 0) {<br>      lk-&gt;locked = 1;<br>      break;<br>    }<br>  }<br>}</p>
<p>然而不幸地是在多处理器上这种实现不会达到互斥。当两个CPU同时对locked进行读取并且结果为0时，它们都会获得这个锁，而这就会违反互斥的性质。因此我们需要第5第6行的执行原子化。<br>由于锁的广泛使用，多核处理器通常会提供该原子指令。在RISC-V中为amoswap r, a，该指令会交换r和a的值。该指令是原子性的，其会通过特殊硬件来防止其他CPU在读写时使用该内存地址。<br>XV6的acquire使用可移植的C库函数<strong>sync_lock_test_and_set，而其在底层是使用amoswap实现的。函数返回值是locked的旧值。acquire函数在循环中不停（自旋）调用swap直到其获得锁。每次循环将1swap到locked中，并判断旧值是否为0，为0就说明获取到了锁，同时swap也将locked设置为了1。如果旧值为1，说明其他CPU持有锁，而swap也并没有改变locked的值。<br>当获取到了锁，acquire就会为了调试而记录获取锁的CPU。lk-&gt;cpu域是被锁保护的并且必须在获取锁后才能被改变。<br>release函数则与acquire相反；该函数清空cpu域并释放锁。理论上释放只需要将locked域置0。而C语言标准运行编译器使用多存储指令来实现赋值，因此一条赋值语句可能不是原子的。因此，release使用C库函数</strong>sync_lock_release来进行原子性赋值。该函数底层也是通过amoswap指令实现。</p>
<h3 id="6-3-代码：使用锁"><a href="#6-3-代码：使用锁" class="headerlink" title="6.3 代码：使用锁"></a>6.3 代码：使用锁</h3><p>XV6在许多地方都使用锁来避免竞争条件。kalloc和kfree是一个很好的例子。使用锁的一个难点是决定要使用多少锁以及每个锁要保护哪些数据和不变性。这里有几个基本原则：首先当一个变量在被一个CPU写入时，有其他CPU可以对其读写时，应该使用锁来避免两个操作重叠；第二，记住锁所保护的不变性，如果一个不变性涉及多个内存位置，则所有的位置都需要被一个单独的锁来保护，从而保证不变性。<br>上述只说了锁什么时候是必要的而没有锁什么时候是不必须的，而减少锁的数量对效率来说是很重要的，因为锁减少了并行。如果并行不是必须的，那么可以只使用一个线程从而不必考虑锁的问题。简单内核可以在多处理器上只使用一个锁，当进入内核态时获取锁，离开时释放锁（尽管系统调用如管道的读和wait将会产生问题）。很多单处理器系统使用这种方法来在多处理器上运行，有的时候被成为“大内核锁”。但是，这种方法破坏了并行性：一次只有一个CPU可以在内核中执行。如果内核要进行任何重计算任务，使用一系列的锁会更加高效，内核可以同时在多个CPU上运行。<br>作为粗粒度锁的例子，XV6的kalloc.c分配器只有一个被一个锁保护的空闲链表。如果多个进程在不同CPU上同时尝试申请页面，那么每一个都需要在acquire中自旋等待。自旋是在做无用功从而降低了性能。如果锁的争用浪费了大量时间，那么可能就要通过改变分配器的设计来提高性能，使用多个空闲链表，每个链表单独持有锁，从而允许真正的并行分配。<br>作为细粒度锁的例子，XV6对于每个文件都有一个单独的锁，因此操作不同文件的进程可以无需等待其他的文件的锁。文件锁模式的粒度可以变得更加的细，如果希望进程同时写相同文件的不同区域。总而言之，锁的粒度需要由性能度量以及锁的复杂性的考虑来决定。</p>
<h3 id="6-4死锁和锁顺序"><a href="#6-4死锁和锁顺序" class="headerlink" title="6.4死锁和锁顺序"></a>6.4死锁和锁顺序</h3><p>如果代码在内核中需要同时持有多个锁，那么有一点很重要，就是获取锁的顺序要相同。如果顺序不同，那么就会有死锁的风险。假设XV6中两个代码路径要获取锁A和B，但是路径1先获取A再获取B，而另一条路径先获取B再获取A。假设线程T1执行代码路径1并获取了锁A，而线程T2执行路径2并获取了锁B。那么接下来T1会尝试获取获取锁B而T2会尝试获取锁A。两个获取就肯定都会被阻塞，因为另一个线程持有需要的锁，并且不会释放直到它的acquire返回。为了避免这种死锁，所有代码路径必须以同样的顺序获取锁。对全局锁获取顺序的需要意味着锁实际上是每个函数规范的一部分：调用者必须以某种方式调用函数，使锁按约定的顺序被获取。<br>XV6有很多长度为2的涉及每个进程的锁的锁顺序链，因为在路径上sleep函数会工作。例如consoleintr是处理输入字符的中断程序。当一个新行到达，任何等待控制台输入的进程就会被唤醒。当调用wakeup时consoleintr持有cons.lock，而wakeup又会获取等待进程的锁来唤醒它。因此，避免全局死锁的锁顺序包含cons.lock锁必须在每个进程锁之前被获取的规则。文件系统代码包含XV6的最长的锁链。例如创建文件需要同时获取目录上的锁，新文件的inode的锁，磁盘块缓冲区的锁，磁盘驱动的vdisk_lock以及调用进程的锁。为了避免死锁，文件系统代码通常要求以一定顺序来获取锁。<br>遵守避免全局死锁的顺序可能会十分困难。有时候锁顺序会与程序结构的逻辑冲突，如模块M1调用模块M2，但是锁顺序要求M2的锁在M1之前获取。有时候也无法预知需要的锁，可能获取一个锁之后才能直到下一个锁是什么。这种情况出现于在文件系统中根据路径名连续查找模块以及wait和exit函数在进程表中查找子进程中。最后，死锁的危险通常会限制锁策略能够使用多细粒度的锁，越多的锁就意味着越多死锁的可能性。在内核实现中，避免死锁通常是很重要的一部分。</p>
<p>###6.5 锁和中断处理程序<br>XV6中有一些自旋锁保护了会同时被线程和中断处理程序使用的数据。例如clockintr定时器中断处理程序可能会增加ticks当一个内核线程同时在sys_sleep函数中读取ticks。tickslock锁会将两个访问串行化。<br>自旋锁和中断的交互会带来潜在的风险。假设sys_sleep持有锁，并且CPU产生了一个定时器中断。clockintr将会尝试申请锁，发现锁被持有，于是等待其被释放。在这种情况下，锁将永远不会被释放：只有sys_sleep会释放锁，但是sys_sleep不会释放锁直到clockintr返回。因此CPU会进入死锁状态，并且其他需要该锁的代码都会被冻结。<br>为了避免这种情况，如果一个自旋锁在中断处理程序中被使用，CPU必须在中断允许时不会持有该锁。XV6更加保守：当CPU申请任何锁时，XV6总是会在该CPU上关闭中断。中断可能仍在其他CPU上发生，因此中断的acquire可以等待一个线程释放自旋锁，只要不在同一个CPU上。<br>XV6会重新允许中断当一个CPU不再持有自旋锁，必须通过一些小的记录来处理嵌套临界区。acquire调用push_off而release调用pop_off来追踪当前CPU的嵌套的层次。当计数器为0时，pop_off恢复最外层临界区开始前的中断允许状态。intr_off和intr_on函数分别执行RISC-V的关和开中断指令。<br>在acquire设置lk-&gt;locked之前调用push_off是非常重要的。如果两者顺序交换，就会有一个小窗口，此时锁被获取而中断是允许的，如果不幸此时发生了中断，就可能会使系统死锁。相同的，release释放锁之后再调用pop_off也是很重要的。</p>
<h3 id="6-6-指令和内存顺序"><a href="#6-6-指令和内存顺序" class="headerlink" title="6.6 指令和内存顺序"></a>6.6 指令和内存顺序</h3><p>自然地会认为程序以源代码语句出现的顺序来执行程序。但在很多编译器和CPU中，代码是乱序执行的从而来获得更高的性能。如果一条指令需要很多个周期来完成，CPU可能会更早地发射指令，使其与其他指令重叠，从而避免CPU停顿。例如CPU可能注意到一串指令序列A和B不依赖彼此，CPU就可能会先执行指令B，因为其输入比A的输入更早就绪或者为了将A和B的执行重叠起来。编译器也可能会进行类似的重排，通过先于源代码中之前的语句的指令发射一条语句的指令。<br>编译器和CPU允许通过不会改变一串代码执行结果的规则来重排语句。然而，这些允许重排的规则会改变并发代码的结果，并且很容易在多处理器上导致错误的行为。CPU的排序规则被成为内存模型。<br>例如push的代码，如果CPU将第4行对应的store指令移动到release之后就会引起灾难：<br>l = malloc(sizeof *l);<br>l-&gt;data = data;<br>acquire(&amp;listlock);<br>l-&gt;next = list;<br>list = l;<br>release(&amp;listlock);</p>
<p>如果这种重排发生了，这里就会有一个窗口使得其他CPU可以获取锁并且更新list，但是看见的并不是初始的list-&gt;next。<br>为了告诉硬件和编译器不要进行这种重排，XV6在acquire和release中使用<strong>sync_synchronize()。</strong>sync_synchronize()是一个内存屏障：它告诉编译器和CPU不要越过屏障重排load和store指令。XV6acquire和release的屏障在几乎所有会出现问题的情况下强制保持顺序，后面的章节会讨论一些例外。</p>
<h3 id="6-7-睡眠锁"><a href="#6-7-睡眠锁" class="headerlink" title="6.7 睡眠锁"></a>6.7 睡眠锁</h3><p>有时候XV6需要长时间持有一个锁。例如文件系统在磁盘上读写文件内容时持有一个文件锁，而这些磁盘操作会耗费数十毫秒。当其他进程要获取锁时，长时间持有自旋锁会引起很大的浪费，因为申请的进程会长时间浪费CPU在自旋上。自旋锁的另一个缺点就是当其保持自旋锁时进程不会让出CPU，我们希望当持有锁的进程在等待磁盘时其他进程能使用CPU。当持有自旋锁时让出CPU是非法的，因为如果第二个线程尝试获取自旋锁时，这可能会导致死锁；因为acquire不会让出CPU，第二个进程的自旋可能会阻止第一个线程运行和释放锁。当持有锁时让出CPU同样违反了当自旋锁被持有时中断必须关闭的需求。因此我们需要一种当acquire等待时能让出CPU以及允许持有锁时让出（和中断）的锁。<br>XV6提供了睡眠锁这种锁、acquiresleep使用下一章讲到的技术使其在等待时会让出CPU。在高层来看，睡眠锁有一个被自旋锁保护的locked域，而acquiresleep调用sleep会原子地让出CPU并释放自旋锁。这使得其他线程可以在acquiresleep等待时执行。<br>因为睡眠锁使中断允许，因此它们不能被用在中断处理程序中。因为acquiresleep会让出CPU，睡眠锁不能在自旋锁保护的临界区内使用（尽管自旋锁可以在睡眠锁保护的临界区内使用）。<br>自旋锁最好在短临界区使用，因为等待它们会浪费CPU时间；睡眠锁在长时间操作上表现更好。<br>真实操作系统<br>尽管并发原语和并行被研究了很多年，锁编程仍然是十分有挑战性的。最好是将锁隐藏在更高级的结构如同步队列中，尽管XV6没有这样做。如果你使用锁来编程，最好使用工具来标识临界区，因为很容易忽略需要获得锁的不变性。<br>大部分操作系统支持POSIX threads（pthreads），这允许用户在不同CPU上并发运行多个线程。Pthreads支持用户级别锁和屏障等。Pthread的支持需要得到操作系统的支持。例如当一个pthread在系统调用中阻塞时，同一个进程的其他pthread应该能够在这个CPU上运行。另一个例子是当一个pthread改变了进程的地址空间（如内存映射），内核应该安排其他运行相同进程的线程的CPU更新页表硬件来映射地址空间上的修改。<br>是有可能不使用原子指令来实现锁的，但是其代价非常高昂，并且大部分操作系统都是使用原子指令。<br>如果很多CPU尝试同时获取一个锁时，锁的代价是非常高昂的。如果一个CPU在本地cache中缓存了一个锁，其他CPU必须获取这个锁，之后原子指令会更新cache行，持有锁必须将cache行从一个CPU的cache复制到其他CPU的cache，并且可能需要使cache行的其他所有内容失效。从另一个CPU的cache中获取cache行的代价可能比从本地cache中获取行要高几个数量级。<br>为了避免锁相关的高昂代价，许多操作系统使用无锁数据结构和算法。如上文中提到的多个空闲内存链表。然而无锁编程比锁编程要更加复杂；例如必须考虑指令和内存重排。锁编程已经很困难了，因此XV6避免了无锁编程带来的额外复杂性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/08/13/MIT6-828笔记/" data-id="cl64cw1jt0004x8w26zc9xgf3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/操作系统/">操作系统</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/02/01/TCP-IP笔记/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          TCP/IP笔记
        
      </div>
    </a>
  
  
    <a href="/2020/08/13/MIT6.828 学习笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">MIT6.828 学习笔记</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ansible/">Ansible</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/">Mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多线程/">多线程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全/">安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/杂记/">杂记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络/">网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Ansible/" style="font-size: 10px;">Ansible</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/多线程/" style="font-size: 10px;">多线程</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/安全/" style="font-size: 10px;">安全</a> <a href="/tags/操作系统/" style="font-size: 20px;">操作系统</a> <a href="/tags/杂记/" style="font-size: 10px;">杂记</a> <a href="/tags/网络/" style="font-size: 10px;">网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/02/01/操作系统笔记/">操作系统笔记</a>
          </li>
        
          <li>
            <a href="/2021/02/01/TCP-IP笔记/">TCP/IP笔记</a>
          </li>
        
          <li>
            <a href="/2020/08/13/MIT6-828笔记/">MIT6.828 学习笔记</a>
          </li>
        
          <li>
            <a href="/2020/08/13/MIT6.828 学习笔记/">MIT6.828 学习笔记</a>
          </li>
        
          <li>
            <a href="/2020/08/13/多线程笔记/">多线程笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Shengxin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>